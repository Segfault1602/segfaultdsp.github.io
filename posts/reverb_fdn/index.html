<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alexandre St-Onge">
<meta name="dcterms.date" content="2025-04-21">

<title>Automatic Optimization of Feedback Delay Networks – SegfaultDSP</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6d5f49080fd7a04518cb6db3008564bf.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-210NT6BWYX"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-210NT6BWYX', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">SegfaultDSP</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/segfault1602"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/2d_mesh_sandbox/index.html">Posts</a></li><li class="breadcrumb-item"><a href="../../posts/reverb_fdn/index.html">Automatic Optimization of Feedback Delay Networks</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/2d_mesh_sandbox/index.html">Posts</a></li><li class="breadcrumb-item"><a href="../../posts/reverb_fdn/index.html">Automatic Optimization of Feedback Delay Networks</a></li></ol></nav>
      <h1 class="title">Automatic Optimization of Feedback Delay Networks</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://segfaultdsp.com">Alexandre St-Onge</a> </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 21, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">April 28, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/2d_mesh_sandbox/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2D Mesh Sandbox</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/reverb_fdn/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Automatic Optimization of Feedback Delay Networks</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Bowed String</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/bowed_string/waveguide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BowedString Part 1: Digital Waveguide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/bowed_string/bow_table.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BowedString Part 2: Bow Table</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/bowed_string/bowed_string_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BowedString Part 3: BowedString audio example</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Phaseshaper</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/phaseshaper/phaseshaper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Phaseshaping Oscillator</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Windowed Sinc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/windowed_sinc/windowed_sinc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Windowed sinc resampling</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="automatic-optimization-of-feedback-delay-networks-using-genetic-algorithms" class="level1 unnumbered">
<h1 class="unnumbered">Automatic Optimization of Feedback Delay Networks using Genetic Algorithms</h1>
</section>
<section id="background" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Background</h1>
<p>Feedback delay networks (FDN) are a common method to render artificial reverberation. Compared to convolution-based methods, FDNs are more flexible and generally have a lower computing cost <span class="citation" data-cites="valimaki_fifty_2012"><a href="#ref-valimaki_fifty_2012" role="doc-biblioref">[1]</a></span>. One of the main drawbacks of FDNs is that they can be difficult to design and wrong choices of parameters can lead to coloration in the reverberated signal. In this work, we will look at methods to automatically optimize the parameters of an FDN to match a target room impulse response (RIR). These methods will usually involve some kind of optimization algorithm, such as genetic algorithms (GA) or gradient descent, to optimize the parameters of the FDN followed by an analysis-synthesis framework to design the attenuation and tonal correction filters needed to match the target RIR. A brief overview of the FDN structure and the analysis-synthesis framework will be given, followed by a review of the existing methods to optimize the parameters of an FDN. Finally, a custom FDN in C++ and Python was developed to attempt to reproduce the results of two papers.</p>
<section id="feedback-delay-networks" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="feedback-delay-networks"><span class="header-section-number">1.1</span> Feedback Delay Networks</h2>
<p>Feedback Delay Networks (FDN) are a class of artificial reverberation algorithms that use several delay lines in a feedback loop in order to produce the reverberated sound <span class="citation" data-cites="valimaki_fifty_2012"><a href="#ref-valimaki_fifty_2012" role="doc-biblioref">[1]</a></span>.</p>
<p>Typical components of a <span class="math inline">\(N\)</span> channel FDN include the input gains <strong><span class="math inline">\(B\)</span></strong>, output gains <strong><span class="math inline">\(C\)</span></strong>, a feedback Matrix <strong><span class="math inline">\(A\)</span></strong>, <span class="math inline">\(N\)</span> parallel delay lines, <span class="math inline">\(N\)</span> attenuation Filters <strong><span class="math inline">\(H(z)\)</span></strong> and a tonal correction Filter <strong><span class="math inline">\(T(z)\)</span></strong>.</p>
<div id="fig-fdn-structure" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fdn-structure-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../assets/reverb_fdn/fdn_structure_jot.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fdn-structure-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Common FDN structure <span class="citation" data-cites="jean-marc_digital_1991"><a href="#ref-jean-marc_digital_1991" role="doc-biblioref">[2]</a></span>
</figcaption>
</figure>
</div>
<p>The output of the FDN is given by the following equation, with <span class="math inline">\(x(t)\)</span> being the input signal and <span class="math inline">\(q_i(t)\)</span> the output of the <span class="math inline">\(i^{th}\)</span> delay line <span class="citation" data-cites="jot_analysissynthesis_1992"><a href="#ref-jot_analysissynthesis_1992" role="doc-biblioref">[3]</a></span>:</p>
<p><span id="eq-fdn-output"><span class="math display">\[
y(t) = \sum_{i=1}^{N} c_i \cdot q_i(t) + d \cdot x(t)
\tag{1}\]</span></span></p>
<p><span id="eq-fdn-output2"><span class="math display">\[
q_j(t+m_j) = \sum_{i=1}^{N} a_{ij} \cdot q_i(t) + b_j \cdot x(t) \qquad (\textrm{for}\ 1 \le j \le N),
\tag{2}\]</span></span></p>
<p>Which becomes in the z-domain:</p>
<p><span id="eq-fdn-output3"><span class="math display">\[
y(z) = c^T \cdot q(z) + d \cdot x(z)
\tag{3}\]</span></span> <span id="eq-fdn-output4"><span class="math display">\[
q(z) = D(z) \cdot [A q(z) + b x(z)],
\tag{4}\]</span></span></p>
<p>where:</p>
<p><span class="math display">\[
q(z) = \begin{bmatrix} q_1(z) \\ q_2(z) \\ \vdots \\ q_N(z) \end{bmatrix} \qquad
D(z) = \begin{bmatrix} z^{-m_1} &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; z^{-m_1} &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; z^{-m_n} \end{bmatrix} \qquad
b = \begin{bmatrix} b_1 \\ b_2 \\ \vdots \\ b_N \end{bmatrix} \qquad
c = \begin{bmatrix} c_1 \\ c_2 \\ \vdots \\ c_N \end{bmatrix} \qquad
A = \begin{bmatrix} a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1N} \\ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2N} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_{N1} &amp; a_{N2} &amp; \cdots &amp; a_{NN} \end{bmatrix}
\]</span></p>
<p>The transfer function of the FDN is then given by:</p>
<p><span id="eq-fdn-transfer"><span class="math display">\[
H(z) = c^T \cdot \left[ D(z^-1) - A \right]^{-1} \cdot b + d
\tag{5}\]</span></span></p>
<p>The <span class="math inline">\((\cdot)^T\)</span> operator is the transpose operation, the matrix <span class="math inline">\(D(z^{-1})\)</span> is the diagonal delay matrix, <span class="math inline">\(A\)</span> is the feedback matrix, <span class="math inline">\(b\)</span> is the input gain vector, <span class="math inline">\(c\)</span> is the output gain vector and <span class="math inline">\(d\)</span> is the direct path gain.</p>
<section id="feedback-matrix" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="feedback-matrix"><span class="header-section-number">1.1.1</span> Feedback Matrix</h3>
<p>The feedback matrix, sometimes called the mixing matrix, is a <span class="math inline">\(N\times N\)</span> matrix that defines how the signal is scattered inside the feedback loop. Ignoring the attenuation filters for a moment, it is often desirable for the FDN to be <em>lossless</em>, which happens when the poles of the system all lie on the unit circle. This can be achieved with the use of a unitary feedback matrix <span class="citation" data-cites="stautner_designing_1982 schlecht_lossless_2017"><a href="#ref-stautner_designing_1982" role="doc-biblioref">[4]</a>, <a href="#ref-schlecht_lossless_2017" role="doc-biblioref">[5]</a></span>. A matrix is said to be unitary if it fulfills the condition:</p>
<p><span class="math display">\[
AA^H=I,
\]</span></p>
<p>where <span class="math inline">\((\cdot)^H\)</span> denotes the Hermitian transpose and <span class="math inline">\(I\)</span> is the identity matrix. Common types of unitary matrices include the <a href="https://ccrma.stanford.edu/~jos/pasp/Hadamard_Matrix.html">Hadamard</a> matrix and the <a href="https://ccrma.stanford.edu/~jos/smith-nam/Householder_Feedback_Matrix.html">Householder</a> matrix. More complex types of matrix have been proposed in recent years with the goal of improving the echo density of the FDN output. Called filter feedback matrix (FFMs) <span class="citation" data-cites="schlecht_scattering_2020"><a href="#ref-schlecht_scattering_2020" role="doc-biblioref">[6]</a></span>, these are matrices where each entry is a finite impulse response (FIR) filter. These FFMs can be implemented efficiently in a cascaded form, where <span class="math inline">\(K\)</span> feedback matrices are separated by a bank of delay lines, as shown in <a href="#fig-ffm" class="quarto-xref">Figure&nbsp;2</a>.</p>
<div id="fig-ffm" class="lightbox quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ffm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../assets/reverb_fdn/ffm_matrix.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;2: FFM structure from [@schlecht_scattering_2020]"><img src="../assets/reverb_fdn/ffm_matrix.png" class="img-fluid figure-img" style="width:50.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ffm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: FFM structure from <span class="citation" data-cites="schlecht_scattering_2020"><a href="#ref-schlecht_scattering_2020" role="doc-biblioref">[6]</a></span>
</figcaption>
</figure>
</div>
</section>
<section id="attenuation-filters" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="attenuation-filters"><span class="header-section-number">1.1.2</span> Attenuation Filters</h3>
<p>Adding attenuation filters inside the feedback loop allows for control of the frequency-dependant decay time of the FDN. Various strategies have been proposed in the literature to design the filters. One of the first proposed methods involved the use of a one-pole lowpass filter<span class="citation" data-cites="jean-marc_digital_1991"><a href="#ref-jean-marc_digital_1991" role="doc-biblioref">[2]</a></span> where the pole of the filter depends on the desired reverberation time (<span class="math inline">\(T_{60}\)</span>) at <span class="math inline">\(dc\)</span> (0Hz) and the Nyquist frequency and further scaled by the delay length of the preceding delay line. More recently, the use of graphic equalizers (GEQ) has been increasingly popular as low-order filters are not accurate enough to model the decay characteristics of real rooms <span class="citation" data-cites="valimaki_two-stage_2024"><a href="#ref-valimaki_two-stage_2024" role="doc-biblioref">[7]</a></span>. Välimäki et al. <span class="citation" data-cites="valimaki_two-stage_2024"><a href="#ref-valimaki_two-stage_2024" role="doc-biblioref">[7]</a></span> proposed a two-stage approach to design the attenuation filter where a low-order low-shelf filter is used to approximate the target magnitude response at the <span class="math inline">\(dc\)</span> and Nyquist frequencies, followed by a higher-order GEQ that can be used to approximate the desired attenuation in multiple frequency bands. The use of the pre-filter eases the design of the GEQ which can become inaccurate if the gain’s variation between bands is greater than 12dB <span class="citation" data-cites="valimaki_two-stage_2024"><a href="#ref-valimaki_two-stage_2024" role="doc-biblioref">[7]</a></span>.</p>
<div id="fig-two-stage-structure" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-stage-structure-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../assets/reverb_fdn/two_stage_struct.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-stage-structure-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Two-stage attenuation filter design from <span class="citation" data-cites="valimaki_two-stage_2024"><a href="#ref-valimaki_two-stage_2024" role="doc-biblioref">[7]</a></span>
</figcaption>
</figure>
</div>
<div id="fig-two-stage-magnitude" class="lightbox quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-stage-magnitude-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../assets/reverb_fdn/two_stage_fig.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;4: Magnitude response of the two-stage attenuation filter design from [@valimaki_two-stage_2024]"><img src="../assets/reverb_fdn/two_stage_fig.png" class="img-fluid figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-stage-magnitude-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Magnitude response of the two-stage attenuation filter design from <span class="citation" data-cites="valimaki_two-stage_2024"><a href="#ref-valimaki_two-stage_2024" role="doc-biblioref">[7]</a></span>
</figcaption>
</figure>
</div>
<p>For this project, an octave band GEQ composed of 10 cascaded biquad filters was used.</p>
</section>
<section id="tonal-correction-filter" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="tonal-correction-filter"><span class="header-section-number">1.1.3</span> Tonal Correction Filter</h3>
<p>A tonal correction filter is added to the output of the FDN to shape the initial energy of the impulse response. Jot <span class="citation" data-cites="jot_analysissynthesis_1992"><a href="#ref-jot_analysissynthesis_1992" role="doc-biblioref">[3]</a></span> explains that the use of attenuation filters introduces a dependence between the reverberation time and the frequency response of the FDN. The tonal correction filter is then used to correct the frequency response of the FDN to match the desired target, which in our case would be a real room impulse response. A common method to obtain the gains of the filter is to look at the initial amplitude of each band of the energy decay curves.</p>
</section>
</section>
</section>
<section id="room-impulse-response-analysis" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Room Impulse Response Analysis</h1>
<p>In order to accurately design the attenuation filters and the tonal correction filter, we will need to analyze the target room impulse response (RIR) to extract the desired reverberation time (<span class="math inline">\(T_{60}\)</span>) at each frequency band. This usually involves looking at the energy decay curves (EDC) of the RIR.</p>
<p>The EDC was first introduced by Schroeder <span class="citation" data-cites="schroeder_new_1965"><a href="#ref-schroeder_new_1965" role="doc-biblioref">[8]</a></span> and is defined as the reverse integral of the squared impulse response <span class="math inline">\(h(t)\)</span>:</p>
<p><span class="math display">\[
EDC(t) = \int_{t}^{+\infty} h^2(\tau) d\tau
\]</span></p>
<p>The impulse response is first filtered through an octave band filter bank to obtain the energy decay curves at each frequency band. The EDCs are then scaled to a dB scale to obtain the reverberation time. Depending on the level of static noise present in the RIR, it might be more accurate to compute the <span class="math inline">\(T_{60}\)</span> using the T15 <span class="citation" data-cites="ibnyahya_method_2022"><a href="#ref-ibnyahya_method_2022" role="doc-biblioref">[9]</a></span>:</p>
<p><span class="math display">\[
T_{60} = 4 \cdot T_{15}
\]</span></p>
<div id="fig-edc" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../assets/reverb_fdn/Octave_Band_EDC.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="EDC curves or a RIR, filtered through an octave band filter bank."><img src="../assets/reverb_fdn/Octave_Band_EDC.png" class="img-fluid figure-img"></a></p>
<figcaption>EDC curves or a RIR, filtered through an octave band filter bank.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../assets/reverb_fdn/Reverberation_time.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Reverberation time (T_{60})."><img src="../assets/reverb_fdn/Reverberation_time.png" class="img-fluid figure-img"></a></p>
<figcaption>Reverberation time (<span class="math inline">\(T_{60}\)</span>).</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-edc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5
</figcaption>
</figure>
</div>
<p>A downside of this method is that the resulting <span class="math inline">\(T_{60}\)</span> can be greatly affected by the choice of the filter bank used to filter the impulse response <span class="citation" data-cites="marbjerg_influence_2018 huszty_effects_2008"><a href="#ref-marbjerg_influence_2018" role="doc-biblioref">[10]</a>, <a href="#ref-huszty_effects_2008" role="doc-biblioref">[11]</a></span>.</p>
<p>Götz et al. <span class="citation" data-cites="gotz_neural_2022"><a href="#ref-gotz_neural_2022" role="doc-biblioref">[12]</a></span> proposed a neural-network-based method for estimating EDCs, called <a href="https://github.com/georg-goetz/DecayFitNet">DecayFitNet</a>. This method should be less sensitive to the presence of static noise in the RIR and was the one used for this project.</p>
<div id="fig-decayfitnet" class="lightbox quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decayfitnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../assets/reverb_fdn/rt60_comparison.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;6: Comparison of the EDCs estimated by DecayFitNet and the EDCs computed using the Schroeder integration."><img src="../assets/reverb_fdn/rt60_comparison.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decayfitnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Comparison of the EDCs estimated by DecayFitNet and the EDCs computed using the Schroeder integration.
</figcaption>
</figure>
</div>
</section>
<section id="automatic-optimization" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Automatic Optimization</h1>
<p>Given the difficulty of choosing the parameters of the FDN manually to obtain satisfactory results, techniques have been proposed to automatically optimize the parameters of the FDN, often with the goal of matching a target RIR.</p>
<p>In <span class="citation" data-cites="michael_generating_2012"><a href="#ref-michael_generating_2012" role="doc-biblioref">[13]</a></span>, Chemistruck et al.&nbsp;used a genetic algorithm (GA) to find the feedback matrix coefficients as well as the cutoff frequencies to the attenuation filters. The FDN architecture used in the experiment was a 4-channel FDN with second-order lowpass filters as attenuation filters. With only 4 channels, the FDN will have difficulties building a realistic echo density, and as such the authors added a diffusion stage to the output of the FDN. The diffusion stage is composed of <span class="math inline">\(N\)</span> parallel delay lines of length <span class="math inline">\(\{ D, \frac{D}{2}, \frac{D}{4}, \ldots, \frac{D}{N} \}\)</span>, with <span class="math inline">\(D\)</span> being less than 300 samples. To evaluate the fitness of the FDN, the amplitude envelope of the FDN output was compared to the amplitude envelope of the target RIR. The difference between each sample was summed up and the FDN with the lowest error was selected. Results of listening tests showed the GA reverb output was consistently rated lower than the output generated through convolution with the target RIR.</p>
<p>In <span class="citation" data-cites="jay_automatic_2016"><a href="#ref-jay_automatic_2016" role="doc-biblioref">[14]</a></span>, Coggin and Pirkle also used GA to optimize the parameters of an FDN. Changes from the previous work include the use of an FIR filter at the input of the FDN to model the early reflections of the target RIR. The coefficients of the FIR filters were obtained by taking the first 80ms of the target RIR. The Hadamard matrix was used as the feedback matrix this time and stayed constant during the optimization. A 16-channel FDN was used. The parameters optimized by the GA were the delay lengths <span class="math inline">\(m\)</span>, the input gains <span class="math inline">\(b\)</span> and the output gains <span class="math inline">\(c\)</span>. Input and output gains were limited to a range of <span class="math inline">\([-1,1]\)</span> and delay lengths were constrained to be integer values less than 100ms. Attenuation and tone correction filters were designed based on the <span class="math inline">\(T_{60}\)</span> of the target RIR. Sixth-order filters were used for the attenuation filters and a 4096-tap FIR filter was used for the tonal correction filter. The fitness function was once again based on the amplitude envelope, but this time the maximum absolute value of the difference between the two amplitude envelopes was used. Listening tests devised to measure the perceptibility of differences between the GA reverb and the convolution reverb showed that the GA reverb was still not able to convincingly match the target RIR.</p>
<p>In <span class="citation" data-cites="ibnyahya_method_2022"><a href="#ref-ibnyahya_method_2022" role="doc-biblioref">[9]</a></span>, Ibnyaha and Reiss introduced a multi-stage approach to optimize the parameters of an FDN. In the first stage, the target impulse response was analyzed using the Schroeder EDC <span class="citation" data-cites="schroeder_new_1965"><a href="#ref-schroeder_new_1965" role="doc-biblioref">[8]</a></span> to obtain the <span class="math inline">\(T_{60}\)</span> at various frequency bands as well as the initial energy of the RIR. This information was used to design the attenuation filters and the tonal correction filter using the graphic equalizer developed by Valimaki et al.&nbsp;in <span class="citation" data-cites="valimaki_accurate_2017"><a href="#ref-valimaki_accurate_2017" role="doc-biblioref">[15]</a></span>. GA was then used to optimize the value of the delay lengths <span class="math inline">\(m\)</span>, the input gains <span class="math inline">\(b\)</span>, the output gains <span class="math inline">\(c\)</span> and the direct gain <span class="math inline">\(d\)</span>. Gains were constrained to values between <span class="math inline">\([-1,1]\)</span> and delay lengths were constrained to be integer values between 2 and 250ms. For the feedback matrix, randomly generated orthogonal matrices were used in a 16-channel FDN configuration. To better match the early reflection and echo density build-up of the target RIR, an FIR filter was used at the input of the FDN. The FIR filter was designed by truncating the RIR at <span class="math inline">\(t=EDT\)</span>, where <span class="math inline">\(EDT\)</span> refers to the <em>early decay time</em>. The fitness function used was:</p>
<p><span class="math display">\[
C(M_{tar},M_{gen}) = \frac{1}{KN} \sum_{i=1}^{K} \sum_{j=1}^{N} |M_{tar}(i,j) - M_{gen}(i,j)|,
\]</span></p>
<p>where <span class="math inline">\(K\)</span> is the number of Mel-frequency cepstral coefficients (MFCC), <span class="math inline">\(N\)</span> is the number of bins, and <span class="math inline">\(M_{tar}\)</span> and <span class="math inline">\(M_{gen}\)</span> are the target and generated impulse response MFCCs.</p>
<p>In <span class="citation" data-cites="santo_differentiable_2023"><a href="#ref-santo_differentiable_2023" role="doc-biblioref">[16]</a></span>, Santos et al.&nbsp;proposed a differentiable FDN architecture that allows optimization of the parameters of the FDN. The main goal of the optimization process is to minimize the coloration of a lossless FDN. The frequency-sampling method is used to approximate the FDN as a finite-impulse-response (FIR) filter by evaluating the transfer function <a href="#eq-fdn-transfer" class="quarto-xref">Equation&nbsp;5</a> at <span class="math inline">\(M\)</span> frequencies. The input gains <span class="math inline">\(b\)</span>, output gains <span class="math inline">\(c\)</span>, and matrix coefficients <span class="math inline">\(W\)</span> are optimized while the delay lengths <span class="math inline">\(m\)</span> are fixed. To ensure that the matrix is unitary, the matrix coefficients <span class="math inline">\(W\)</span> are mapped using the equation: <span class="math display">\[
U = e^{W_{Tr} - W_{Tr}^\intercal},
\]</span></p>
<p>where <span class="math inline">\(W_{Tr}\)</span> is the upper triangular part of the matrix <span class="math inline">\(W\)</span> and the operator <span class="math inline">\((\cdot)^\intercal\)</span> is the transpose operation <span class="citation" data-cites="santo_differentiable_2023"><a href="#ref-santo_differentiable_2023" role="doc-biblioref">[16]</a></span>. Two cost functions were used for the colorless optimization. The first cost function <span class="math inline">\(L_{spectral}\)</span> minimizes the mean-squared error between the magnitude response of the FDN and a theoretical flat magnitude response. The second cost function, <span class="math inline">\(L_{temporal}\)</span>, is there to penalize sparseness in the coefficients of the feedback matrix as it was found that using <span class="math inline">\(L_{spectral}\)</span> alone would often cause the feedback matrix to converge towards a diagonal matrix <span class="citation" data-cites="santo_differentiable_2023"><a href="#ref-santo_differentiable_2023" role="doc-biblioref">[16]</a></span>. Analysis of the modal distribution of the output IR as well as listening tests showed that their method was able to reduce coloration in the FDN output. Audio examples are <a href="http://research.spa.aalto.fi/publications/papers/dafx23-colorless-fdn/">available online</a>.</p>
<p>In <span class="citation" data-cites="santo_rir2fdn_2024"><a href="#ref-santo_rir2fdn_2024" role="doc-biblioref">[17]</a></span>, Santos et al.&nbsp;used their differentiable FDN in an analysis-synthesis framework to match a target RIR. Once a colorless FDN was obtained using the previously described method, DecayFitNet <span class="citation" data-cites="gotz_neural_2022"><a href="#ref-gotz_neural_2022" role="doc-biblioref">[12]</a></span> was used to estimate the <span class="math inline">\(T_{60}\)</span> of the target RIR and the two-stage approach from <span class="citation" data-cites="valimaki_two-stage_2024"><a href="#ref-valimaki_two-stage_2024" role="doc-biblioref">[7]</a></span> was used to design the attenuation filters. The tonal correction filter was designed using the same method but with the pre-filter omitted. Once again, an FIR filter was used to model the early reflections of the target RIR. The FIR filter was designed using the first 2 ms of the target RIR. The amplitude of the FDN output was then further adjusted to match the root mean square of the target RIR. To help with echo density, the unitary matrix used in <span class="citation" data-cites="santo_differentiable_2023"><a href="#ref-santo_differentiable_2023" role="doc-biblioref">[16]</a></span> was replaced with a scattering feedback matrix <span class="citation" data-cites="schlecht_scattering_2020"><a href="#ref-schlecht_scattering_2020" role="doc-biblioref">[6]</a></span> with four stages where each stage is a different optimized Householder matrix. The transposed configuration (see <a href="#fig-transpose-fdn" class="quarto-xref">Figure&nbsp;7</a>) of the FDN was also used, with the claim that it accelerates the echo build-up <span class="citation" data-cites="santo_rir2fdn_2024"><a href="#ref-santo_rir2fdn_2024" role="doc-biblioref">[17]</a></span>. Audio examples are <a href="http://research.spa.aalto.fi/publications/papers/dafx24-rir2fdn/">available online</a>.</p>
<div id="fig-transpose-fdn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-transpose-fdn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../assets/reverb_fdn/transpose_fdn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Transposed FDN from [@santo_rir2fdn_2024]"><img src="../assets/reverb_fdn/transpose_fdn.png" class="img-fluid figure-img" style="width:50.0%"></a></p>
<figcaption>Transposed FDN from <span class="citation" data-cites="santo_rir2fdn_2024"><a href="#ref-santo_rir2fdn_2024" role="doc-biblioref">[17]</a></span></figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-transpose-fdn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7
</figcaption>
</figure>
</div>
</section>
<section id="implementation---matchreverb" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Implementation - MatchReverb</h1>
<p>In <span class="citation" data-cites="ibnyahya_method_2022"><a href="#ref-ibnyahya_method_2022" role="doc-biblioref">[9]</a></span>, Ibnyahya and Reiss implemented their system in MATLAB using the FDN Toolbox <span class="citation" data-cites="schlecht_fdntb_2020"><a href="#ref-schlecht_fdntb_2020" role="doc-biblioref">[18]</a></span>. While the FDN toolbox is an indispensable tool for the analysis and synthesis of FDNs, it can also be slow, which is a notable drawback when using an optimization algorithm such as GA as it will restrict the number of solutions that can be explored in a given amount of time. For this reason, a custom FDN implementation was developed in C++. A Python binding was also created to allow the FDN to be used in a Python environment to take advantage of the existing optimization libraries, such as <a href="https://pygad.readthedocs.io/en/latest/">PyGAD</a>. The C++ implementation shows up to a 100x speedup compared to the FDN Toolbox. Another advantage of the C++ implementation is that it allows the use of the FDN in real-time scenarios such as gaming or virtual-reality applications.</p>
<section id="results" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="results"><span class="header-section-number">4.1</span> Results</h2>
<p>The MATLAB implementation of <span class="citation" data-cites="ibnyahya_method_2022"><a href="#ref-ibnyahya_method_2022" role="doc-biblioref">[9]</a></span> (MatchReverb) was available online and was used to generate the following RIRs. The genetic optimization was performed over 5 generations with a population of 50 individuals per generation and took 23 minutes to optimze 3 FDNs. The ‘Hybrid’ column was generated using the method described earlier with some modification, while the ‘FDN Only’ column uses the same method, but without the early reflection FIR filter. The target RIRs were taken from the MIT RIR survey<span class="citation" data-cites="traer_statistics_2016"><a href="#ref-traer_statistics_2016" role="doc-biblioref">[19]</a></span> and can be found <a href="https://mcdermottlab.mit.edu/Reverb/IR_Survey.html">online</a>. Three rooms were chosen for the analysis-synthesis: <code>h001_bedroom</code>, <code>h025_diningroom</code>, and <code>h042_hallway</code>, with average reverberation times of 0.30, 0.94 and 2.02 seconds respectively<span class="citation" data-cites="santo_rir2fdn_2024"><a href="#ref-santo_rir2fdn_2024" role="doc-biblioref">[17]</a></span>. The optimization time for the three rooms was around 10 minutes. Some of the modifications found in the source code, which were not in the original paper, include a modification to the fitness function that now takes into account the mean error between the target RIR EDC and the synthesized ones, as well as a bug in the scripts that causes the output gains of the FDN to be set to 1. Another interesting aspect of the implementation is that, while the paper claims the tone correction filter is designed in the analysis stage (ie. before the optimization), the implementation actually first generates an impulse response without any tone filter and then the filter is designed using the energy difference between the initial spectrum of the optimized FDN and the initial spectrum of the target RIR. Furthermore, the paper claims to use the MFCCs of the impulse responses to compute the fitness function, but the implementation actually uses the mel spectrogram of the impulse responses.</p>
<p>While the results of the hybrid FDN sound quite close to the reference RIR, the poor results of the FDN-only version might suggest that the early reflection FIR is doing most of the heavy lifting. The ‘Replica’ column was generated using my own reimplementation of the hybrid FDN. My version of the genetic algorithm was performed over 40 generations with a population of 50 individual and took 11 minutes to optimize the 3 FDNs. The higher generation number did not translate into much better results, as it was found that the FDNs tended to converge towards a local minimum in the first 10 generations.</p>
<section id="impulse-responses" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="impulse-responses"><span class="header-section-number">4.1.1</span> Impulse responses</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RIR</th>
<th style="text-align: center;">Reference</th>
<th style="text-align: center;">MatchReverb - Hybrid</th>
<th style="text-align: center;">MatchReverb - FDN Only</th>
<th style="text-align: center;">Replica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bedroom</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h001_Bedroom_65txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h001_Bedroom_mr_50p_5g.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/fdn_only_h001_Bedroom_mr_50p_5g.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h001_Bedroom.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="even">
<td style="text-align: center;">Dining Room</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h025_Diningroom_8txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h025_Diningroom_mr_50p_5g.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/fdn_only_h025_Diningroom_mr_50p_5g.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h025_Diningroom.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Hallway</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h042_Hallway_ElementarySchool_4txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h042_Hallway_mr_50p_5g.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/fdn_only_h042_Hallway_mr_50p_5g.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h042_Hallway.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
</tbody>
</table>
</section>
<section id="audio-examples---percussion" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="audio-examples---percussion"><span class="header-section-number">4.1.2</span> Audio Examples - Percussion</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RIR</th>
<th style="text-align: center;">Reference</th>
<th style="text-align: center;">MatchReverb - Hybrid</th>
<th style="text-align: center;">MatchReverb - FDN Only</th>
<th style="text-align: center;">Replica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bedroom</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h001_Bedroom_ref_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h001_Bedroom_mr_hybrid_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h001_Bedroom_mr_fdnonly_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h001_Bedroom_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="even">
<td style="text-align: center;">Dining Room</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h025_Diningroom_ref_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h025_Diningroom_mr_hybrid_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h025_Diningroom_mr_fdnonly_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h025_Diningroom_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Hallway</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h042_Hallway_ref_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h042_Hallway_mr_hybrid_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h042_Hallway_mr_fdnonly_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h042_Hallway_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
</tbody>
</table>
</section>
<section id="audio-examples---drums" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="audio-examples---drums"><span class="header-section-number">4.1.3</span> Audio Examples - Drums</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RIR</th>
<th style="text-align: center;">Reference</th>
<th style="text-align: center;">MatchReverb - Hybrid</th>
<th style="text-align: center;">MatchReverb - FDN Only</th>
<th style="text-align: center;">Replica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bedroom</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h001_Bedroom_ref_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h001_Bedroom_mr_hybrid_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h001_Bedroom_mr_fdnonly_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h001_Bedroom_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="even">
<td style="text-align: center;">Dining Room</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h025_Diningroom_ref_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h025_Diningroom_mr_hybrid_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h025_Diningroom_mr_fdnonly_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h025_Diningroom_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Hallway</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h042_Hallway_ref_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h042_Hallway_mr_hybrid_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/matchreverb/h042_Hallway_mr_fdnonly_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/mr_replica/mr_cppfdn_h042_Hallway_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="error-visualization" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="error-visualization"><span class="header-section-number">4.2</span> Error visualization</h2>
<p><a href="#fig-error-visualization" class="quarto-xref">Figure&nbsp;8</a> shows the mel spectrogram of the target RIR (left), the FDN output (middle), and the error between the two (right). The error is the absolute difference between the two spectrograms, with a mean error of ~2dB. Even though the error between the two spectrograms is small, the FDN output still sounds noticeably different from the target RIR. This suggests that a fitness function solely based on the spectrogram is not sufficient to accurately match the target RIR using GA.</p>
<div id="fig-error-visualization" class="lightbox quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-error-visualization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../assets//reverb_fdn/fig_mel_error.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;8: Mel spectrogram of the target RIR (right), the FDN output (middle), and the error between the two (left). The error is the absolute difference between the two spectrograms."><img src="../assets//reverb_fdn/fig_mel_error.png" class="img-fluid figure-img" style="width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-error-visualization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Mel spectrogram of the target RIR (right), the FDN output (middle), and the error between the two (left). The error is the absolute difference between the two spectrograms.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="implementation---rir2fdn" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Implementation - RIR2FDN</h1>
<p>In <span class="citation" data-cites="santo_rir2fdn_2024 santo_differentiable_2023 santo_efficient_2024"><a href="#ref-santo_differentiable_2023" role="doc-biblioref">[16]</a>, <a href="#ref-santo_rir2fdn_2024" role="doc-biblioref">[17]</a>, <a href="#ref-santo_efficient_2024" role="doc-biblioref">[20]</a></span>, Santos et al.&nbsp;implemented the differentiable FDN in the frequency domain using the frequency sampling method. The optimization is implemented in PyTorch and uses the Adam optimizer to optimize a colorless FDN. Once the parameters are optimized, the FDN Toolbox <span class="citation" data-cites="schlecht_fdntb_2020"><a href="#ref-schlecht_fdntb_2020" role="doc-biblioref">[18]</a></span> is used to render the final impulse response. The code is available online, as well as audio <a href="http://research.spa.aalto.fi/publications/papers/dafx24-rir2fdn/">examples</a>. The implementation uses 1/3-octave band filters for the attenuation and tone correction filters.</p>
<p>I reimplemented the analysis-synthesis framework using my own FDN implementation. The PyTorch optimization was replaced with a genetic algorithm as one of the goals of this experiment is to see if the colorless optimization can be done successfully on a real-time FDN implementation, bypassing the need to build a differentiable proxy as is often done in the literature<span class="citation" data-cites="mezza_data-driven_2024 mezza_modeling_2024"><a href="#ref-mezza_data-driven_2024" role="doc-biblioref">[21]</a>, <a href="#ref-mezza_modeling_2024" role="doc-biblioref">[22]</a></span>. The 1/3 octave band filters used in the original implementation were replaced by octave band filters to keep CPU usage low and to see how lower-order filters would affect the results. Audio examples of the optimized FDN, where the scattering matrix was replaced by a simple Householder matrix, are included to better demonstrate the effect of the scattering matrix.</p>
<section id="result" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="result"><span class="header-section-number">5.1</span> Result</h2>
<section id="impulse-responses-1" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="impulse-responses-1"><span class="header-section-number">5.1.1</span> Impulse responses</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RIR</th>
<th style="text-align: center;">Reference</th>
<th style="text-align: center;">FDN</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bedroom</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h001_Bedroom_65txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_difffdn_h001_Bedroom_65txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="even">
<td style="text-align: center;">Dining Room</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h025_Diningroom_8txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_difffdn_h025_Diningroom_8txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Hallway</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h042_Hallway_ElementarySchool_4txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_difffdn_h042_Hallway_ElementarySchool_4txts_48000.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
</tbody>
</table>
</section>
<section id="audio-examples---percussion-1" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="audio-examples---percussion-1"><span class="header-section-number">5.1.2</span> Audio Examples - Percussion</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RIR</th>
<th style="text-align: center;">Reference</th>
<th style="text-align: center;">FDN - Scattering</th>
<th style="text-align: center;">FDN - Householder</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bedroom</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h001_Bedroom_ref_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_h001_Bedroom_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_diff_h001_Bedroom_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="even">
<td style="text-align: center;">Dining Room</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h025_Diningroom_ref_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_h025_Diningroom_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_diff_h025_Diningroom_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Hallway</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h042_Hallway_ref_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_h042_Hallway_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_diff_h042_Hallway_ericderr.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
</tbody>
</table>
</section>
<section id="audio-examples---drums-1" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="audio-examples---drums-1"><span class="header-section-number">5.1.3</span> Audio Examples - Drums</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RIR</th>
<th style="text-align: center;">Reference</th>
<th style="text-align: center;">FDN - Scattering</th>
<th style="text-align: center;">FDN - Householder</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bedroom</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h001_Bedroom_ref_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_h001_Bedroom_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_diff_h001_Bedroom_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="even">
<td style="text-align: center;">Dining Room</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h025_Diningroom_ref_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_h025_Diningroom_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_diff_h025_Diningroom_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Hallway</td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/refs/h042_Hallway_ref_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_h042_Hallway_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
<td style="text-align: center;"><figure class="figure"><audio controls="" src="../assets/reverb_fdn/audio/rir2fdn/ga_diff_h042_Hallway_drums.wav" type="audio/wav">Your browser does not support the audio tag.</audio><figcaption></figcaption></figure></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="error-visualization-1" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="error-visualization-1"><span class="header-section-number">5.2</span> Error visualization</h2>
<p><a href="#fig-spectral_loss" class="quarto-xref">Figure&nbsp;9</a> shows the magnitude response of the FDN before and after optimization. The optimized FDN shows a magnitude response with a greater number of peaks and a lower standard deviation. Another useful visualization can be achieved by plotting only the peaks of the full magnitude response. It shows that the distribution of the peaks is much narrower after optimization, which should result in less coloration in the resulting impulse response <span class="citation" data-cites="heldmann_role_2021"><a href="#ref-heldmann_role_2021" role="doc-biblioref">[23]</a></span>.</p>
<div id="fig-spectral_loss" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spectral_loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../assets/reverb_fdn/spectral_loss.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Magnitude response between 10 and 12 kHz of a colorless FDN before optimization (top) and after optimization (bottom)."><img src="../assets/reverb_fdn/spectral_loss.png" class="img-fluid figure-img" style="width:60.0%"></a></p>
<figcaption>Magnitude response between 10 and 12 kHz of a colorless FDN before optimization (top) and after optimization (bottom).</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../assets/reverb_fdn/spectral_loss_peaks.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Magnitude response before (top) and after (bottom) optimization. Only the peaks of the response are plotted"><img src="../assets/reverb_fdn/spectral_loss_peaks.png" class="img-fluid figure-img" style="width:60.0%"></a></p>
<figcaption>Magnitude response before (top) and after (bottom) optimization. Only the peaks of the response are plotted</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-spectral_loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9
</figcaption>
</figure>
</div>
</section>
</section>
<section id="conclusion" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Conclusion</h1>
<p>In this work, we looked into the automatic optimization of feedback delay networks using a genetic algorithm. A real-time FDN implementation was developed in C++ and used within a Python environment to take advantage of the existing optimization libraries. A reimplementation of the methodologies described in <span class="citation" data-cites="ibnyahya_method_2022"><a href="#ref-ibnyahya_method_2022" role="doc-biblioref">[9]</a></span> and <span class="citation" data-cites="santo_differentiable_2023 santo_rir2fdn_2024"><a href="#ref-santo_differentiable_2023" role="doc-biblioref">[16]</a>, <a href="#ref-santo_rir2fdn_2024" role="doc-biblioref">[17]</a></span> was performed using this new FDN implementation to demonstrate that similar results could be achieved. A potential next step would be to integrate the real-time FDN implementation as a layer of a deep neural network to allow for end-to-end training of the FDN parameters, similar to what was done in <span class="citation" data-cites="ramirez_differentiable_2021"><a href="#ref-ramirez_differentiable_2021" role="doc-biblioref">[24]</a></span>.</p>
</section>
<section id="apendix" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Apendix</h1>
<section id="spectrograms-of-synthesized-impulse-responses" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="spectrograms-of-synthesized-impulse-responses"><span class="header-section-number">7.1</span> Spectrograms of synthesized impulse responses</h2>
<p>Impulse responses and spectrograms of the target RIR, the synthesized RIR using GA and the synthesized RIR using RIR2FDN. The orange line indicates the echo density profile as proposed by <span class="citation" data-cites="abel_simple_2006"><a href="#ref-abel_simple_2006" role="doc-biblioref">[25]</a></span>. The red line indicates the time at which the echo density profile reaches a value of 1.</p>
<div id="fig-rir-comparison" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rir-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><a href="../assets/reverb_fdn/rir_comparison_h001_Bedroom.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;10: "><img src="../assets/reverb_fdn/rir_comparison_h001_Bedroom.png" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><a href="../assets/reverb_fdn/rir_comparison_h025_Diningroom.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;10: "><img src="../assets/reverb_fdn/rir_comparison_h025_Diningroom.png" class="img-fluid figure-img"></a></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rir-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: <a href="../assets/reverb_fdn/rir_comparison_h042_Hallway.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;10: "><img src="../assets/reverb_fdn/rir_comparison_h042_Hallway.png" class="img-fluid figure-img" style="width:50.0%"></a>
</figcaption>
</figure>
</div>
</section>
<section id="fdn-performance" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="fdn-performance"><span class="header-section-number">7.2</span> FDN performance</h2>
<p>Benchmarks of various FDN configurations. The only difference between the configurations is the number of cascaded biquads used in the attenuation and tone correction filters. A Householder matrix was used as the feedback matrix.</p>
<ul>
<li>Blue: 11 cascaded biquads (i.e.&nbsp;octave band filters)</li>
<li>Orange: 32 cascaded biquads (i.e.&nbsp;1/3-octave band filters)</li>
<li>Green: 1 biquad</li>
</ul>
<p>The benchmarks were performed on a 2024 MacBook Air M3 using the microbenchmarking library <a href="https://nanobench.ankerl.com/">nanobench</a> and measured the time taken to render 1 second of audio at 48kHz.</p>
<p><a href="../assets/reverb_fdn/fdn_perf.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="../assets/reverb_fdn/fdn_perf.png" class="img-fluid" style="width:80.0%"></a></p>
</section>
<section id="references" class="level2" data-number="7.3">




</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">7.3 References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-valimaki_fifty_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">V. Valimaki, J. D. Parker, L. Savioja, J. O. Smith, and J. S. Abel, <span>“Fifty years of artificial reverberation,”</span> <em><span>IEEE</span> Transactions on Audio, Speech, and Language Processing</em>, vol. 20, no. 5, pp. 1421–1448, Jul. 2012, doi: <a href="https://doi.org/10.1109/TASL.2012.2189567">10.1109/TASL.2012.2189567</a>.</div>
</div>
<div id="ref-jean-marc_digital_1991" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">jot jean-marc and chaigne antoine, <span>“Digital delay networks for designing artificial reverberators,”</span> <em>journal of the audio engineering society</em>, no. 3030, Feb. 1991.</div>
</div>
<div id="ref-jot_analysissynthesis_1992" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">J.-M. Jot, <span>“An analysis/synthesis approach to real-time artificial reverberation,”</span> in <em>[Proceedings] <span>ICASSP</span>-92: 1992 <span>IEEE</span> international conference on acoustics, speech, and signal processing</em>, Mar. 1992, pp. 221–224 vol.2. doi: <a href="https://doi.org/10.1109/ICASSP.1992.226080">10.1109/ICASSP.1992.226080</a>.</div>
</div>
<div id="ref-stautner_designing_1982" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">J. Stautner and M. Puckette, <span>“Designing multi-channel reverberators,”</span> <em>Computer Music Journal</em>, vol. 6, no. 1, p. 52, 1982, doi: <a href="https://doi.org/10.2307/3680358">10.2307/3680358</a>.</div>
</div>
<div id="ref-schlecht_lossless_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">S. J. Schlecht and E. A. P. Habets, <span>“On lossless feedback delay networks,”</span> <em><span>IEEE</span> Trans. Signal Process.</em>, vol. 65, no. 6, pp. 1554–1564, Mar. 2017, doi: <a href="https://doi.org/10.1109/TSP.2016.2637323">10.1109/TSP.2016.2637323</a>.</div>
</div>
<div id="ref-schlecht_scattering_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">S. J. Schlecht and E. A. P. Habets, <span>“Scattering in feedback delay networks.”</span> <span>arXiv</span>, Jun. 06, 2020. doi: <a href="https://doi.org/10.48550/arXiv.1912.08888">10.48550/arXiv.1912.08888</a>.</div>
</div>
<div id="ref-valimaki_two-stage_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">V. Välimäki, K. Prawda, and S. J. Schlecht, <span>“Two-stage attenuation filter for artificial reverberation,”</span> <em><span>IEEE</span> Signal Processing Letters</em>, vol. 31, pp. 391–395, 2024, doi: <a href="https://doi.org/10.1109/LSP.2024.3352510">10.1109/LSP.2024.3352510</a>.</div>
</div>
<div id="ref-schroeder_new_1965" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">M. R. Schroeder, <span>“New method of measuring reverberation time,”</span> <em>The Journal of the Acoustical Society of America</em>, vol. 37, no. 3, pp. 409–412, Mar. 1965, doi: <a href="https://doi.org/10.1121/1.1909343">10.1121/1.1909343</a>.</div>
</div>
<div id="ref-ibnyahya_method_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">I. Ibnyahya and J. D. Reiss, <span>“A method for matching room impulse responses with feedback delay networks,”</span> 2022.</div>
</div>
<div id="ref-marbjerg_influence_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">G. Marbjerg, J. Brunskog, C.-H. Jeong, and V. Zapata-Rodriguez, <span>“The influence of overlapping band filters on octave band decay curves,”</span> <em>Acta Acustica united with Acustica</em>, vol. 104, no. 6, pp. 943–946, Nov. 2018, doi: <a href="https://doi.org/10.3813/AAA.919259">10.3813/AAA.919259</a>.</div>
</div>
<div id="ref-huszty_effects_2008" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">C. Huszty, N. Bukuli, Á. Torma, and F. Augusztinovicz, <span>“Effects of filtering of room impulse responses on room acoustics parameters by using different filter structures,”</span> <em>The Journal of the Acoustical Society of America</em>, vol. 123, no. 5, pp. 3617–3617, May 2008, doi: <a href="https://doi.org/10.1121/1.2934828">10.1121/1.2934828</a>.</div>
</div>
<div id="ref-gotz_neural_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">G. Götz, R. Falcón Pérez, S. J. Schlecht, and V. Pulkki, <span>“Neural network for multi-exponential sound energy decay analysis,”</span> <em>The Journal of the Acoustical Society of America</em>, vol. 152, no. 2, pp. 942–953, Aug. 2022, doi: <a href="https://doi.org/10.1121/10.0013416">10.1121/10.0013416</a>.</div>
</div>
<div id="ref-michael_generating_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">chemistruck michael, marcolini kyle, and pirkle will, <span>“Generating matrix coefficients for feedback delay networks using genetic algorithm,”</span> <em>journal of the audio engineering society</em>, no. 8795, Oct. 2012.</div>
</div>
<div id="ref-jay_automatic_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">coggin jay and pirkle will, <span>“Automatic design of feedback delay network reverb parameters for impulse response matching,”</span> <em>journal of the audio engineering society</em>, no. 9666, Sep. 2016.</div>
</div>
<div id="ref-valimaki_accurate_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">V. Valimaki and J. Liski, <span>“Accurate cascade graphic equalizer,”</span> <em><span>IEEE</span> Signal Process. Lett.</em>, vol. 24, no. 2, pp. 176–180, Feb. 2017, doi: <a href="https://doi.org/10.1109/LSP.2016.2645280">10.1109/LSP.2016.2645280</a>.</div>
</div>
<div id="ref-santo_differentiable_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">G. D. Santo, K. Prawda, S. J. Schlecht, and V. Välimäki, <span>“Differentiable feedback delay network for colorless reverberation,”</span> 2023.</div>
</div>
<div id="ref-santo_rir2fdn_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">G. D. Santo, B. Alary, K. Prawda, S. Schlecht, and V. Välimäki, <span>“<span>RIR</span>2FDN: An improved room impulse response analysis and synthesis,”</span> 2024.</div>
</div>
<div id="ref-schlecht_fdntb_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">S. J. Schlecht, <span>“<span>FDNTB</span>: The feedback delay network toolbox,”</span> 2020.</div>
</div>
<div id="ref-traer_statistics_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">J. Traer and J. H. McDermott, <span>“Statistics of natural reverberation enable perceptual separation of sound and space,”</span> <em>Proc. Natl. Acad. Sci. U.S.A.</em>, vol. 113, no. 48, Nov. 2016, doi: <a href="https://doi.org/10.1073/pnas.1612524113">10.1073/pnas.1612524113</a>.</div>
</div>
<div id="ref-santo_efficient_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">G. D. Santo, K. Prawda, S. J. Schlecht, and V. Välimäki, <span>“Efficient optimization of feedback delay networks for smooth reverberation.”</span> <span>arXiv</span>, Aug. 28, 2024. doi: <a href="https://doi.org/10.48550/arXiv.2402.11216">10.48550/arXiv.2402.11216</a>.</div>
</div>
<div id="ref-mezza_data-driven_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">A. I. Mezza, R. Giampiccolo, E. De Sena, and A. Bernardini, <span>“Data-driven room acoustic modeling via differentiable feedback delay networks with learnable delay lines,”</span> <em>J <span>AUDIO</span> <span>SPEECH</span> <span>MUSIC</span> <span>PROC</span>.</em>, vol. 2024, no. 1, p. 51, Oct. 2024, doi: <a href="https://doi.org/10.1186/s13636-024-00371-5">10.1186/s13636-024-00371-5</a>.</div>
</div>
<div id="ref-mezza_modeling_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">A. I. Mezza, R. Giampiccolo, and A. Bernardini, <span>“Modeling the frequency-dependent sound energy decay of acoustic environments with differentiable feedback delay networks,”</span> 2024.</div>
</div>
<div id="ref-heldmann_role_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">J. Heldmann and S. J. Schlecht, <span>“The role of modal excitation in colorless reverberation,”</span> in <em>2021 24th international conference on digital audio effects (<span>DAFx</span>)</em>, Vienna, Austria: <span>IEEE</span>, Sep. 2021, pp. 206–213. doi: <a href="https://doi.org/10.23919/DAFx51585.2021.9768217">10.23919/DAFx51585.2021.9768217</a>.</div>
</div>
<div id="ref-ramirez_differentiable_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">M. A. M. Ramírez, O. Wang, P. Smaragdis, and N. J. Bryan, <span>“Differentiable signal processing with black-box audio effects.”</span> <span>arXiv</span>, May 11, 2021. doi: <a href="https://doi.org/10.48550/arXiv.2105.04752">10.48550/arXiv.2105.04752</a>.</div>
</div>
<div id="ref-abel_simple_2006" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">J. S. Abel and P. Huang, <span>“A simple, robust measure of reverberation echo density,”</span> <em>Audio Eng. Soc. Conv.</em>, 2006.</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/segfaultdsp\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>